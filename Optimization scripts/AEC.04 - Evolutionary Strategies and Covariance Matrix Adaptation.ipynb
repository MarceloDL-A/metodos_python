{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align='left' style=\"width:400px;height:120px;overflow:hidden;\">\n",
    "<a href='http://www.uff.br'>\n",
    "<img align='left' style='display: block;height: 92%' src='https://github.com/lmarti/jupyter_custom/raw/master/imgs/uff.png' alt='UFF logo' title='UFF logo'/>\n",
    "</a>\n",
    "<a href='http://www.ic.uff.br'>\n",
    "<img align='left' style='display: block;height: 100%' src='https://github.com/lmarti/jupyter_custom/raw/master/imgs/logo-ic.png' alt='IC logo' title='IC logo'/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Understanding evolutionary strategies and covariance matrix adaptation\n",
    "\n",
    "## Luis Martí, [IC](http://www.ic.uff.br)/[UFF](http://www.uff.br)\n",
    "\n",
    "[http://lmarti.com](http://lmarti.com); [lmarti@ic.uff.br](mailto:lmarti@ic.uff.br) \n",
    "\n",
    "[Advanced Evolutionary Computation: Theory and Practice](http://lmarti.com/aec-2014) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The notebook is better viewed rendered as slides. You can convert it to slides and view them by:\n",
    "- using [nbconvert](http://ipython.org/ipython-doc/1/interactive/nbconvert.html) with a command like:\n",
    "  ```bash\n",
    "  $ ipython nbconvert --to slides --post serve <this-notebook-name.ipynb>\n",
    "  ```\n",
    "- installing [Reveal.js - Jupyter/IPython Slideshow Extension](https://github.com/damianavila/live_reveal)\n",
    "- using the online [IPython notebook slide viewer](https://slideviewer.herokuapp.com/) (some slides of the notebook might not be properly rendered).\n",
    "\n",
    "This and other related IPython notebooks can be found at the course github repository:\n",
    "* [https://github.com/lmarti/evolutionary-computation-course](https://github.com/lmarti/evolutionary-computation-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm \n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['text.latex.preamble'] ='\\\\usepackage{libertine}\\n\\\\usepackage[utf8]{inputenc}'\n",
    "\n",
    "import seaborn\n",
    "seaborn.set(style='whitegrid')\n",
    "seaborn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistics recap\n",
    "\n",
    "* [Random variable](http://en.wikipedia.org/wiki/Random_variable): a variable whose value is subject to variations due to __chance__. A random variable can take on a set of possible different values, each with an associated probability, in contrast to other mathematical variables.\n",
    "\n",
    "* [Probability distribution](http://en.wikipedia.org/wiki/Probability_distribution): mathematical function describing the possible values of a random variable and their associated probabilities.\n",
    "\n",
    "* [Probability density function (pdf)](http://en.wikipedia.org/wiki/Probability_density_function) of a __continuous random variable__ is a function that describes the relative likelihood for this random variable to take on a given value. \n",
    "     * The probability of the random variable falling within a particular range of values is given by the integral of this variable’s density over that range.\n",
    "     * The probability density function is nonnegative everywhere, and its integral over the entire space is equal to one.\n",
    "     \n",
    "<img src='http://upload.wikimedia.org/wikipedia/commons/2/25/The_Normal_Distribution.svg' width='50%' align='center'/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Moments](http://en.wikipedia.org/wiki/Moment_(mathematics)\n",
    "\n",
    "The probability distribution of a random variable is often characterised by a small number of parameters, which also have a practical interpretation.\n",
    "\n",
    "* [Mean](http://en.wikipedia.org/wiki/Mean) (a.k.a expected value) refers to one measure of the central tendency either of a probability distribution or of the random variable characterized by that distribution.\n",
    "    * population mean: $\\mu = \\operatorname{E}[X]$.\n",
    "    * estimation of sample mean: $\\bar{x}$.\n",
    "* [Standard deviation](http://en.wikipedia.org/wiki/Standard_deviation) measures the amount of variation or dispersion from the mean.\n",
    "    * population deviation:\n",
    "    $$\n",
    "\\sigma = \\sqrt{\\operatorname E[X^2]-(\\operatorname E[X])^2} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}.\n",
    "$$\n",
    "    * unbiased estimator:\n",
    "    $$ \n",
    "    s^2 = \\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2.\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample1 = np.random.normal(0, 0.5, 1000)\n",
    "sample2 = np.random.normal(1,1,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_normal_sample(sample, mu, sigma):\n",
    "    'Plots an histogram and the normal distribution corresponding to the parameters.'\n",
    "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
    "    plt.plot(x, norm.pdf(x, mu, sigma), 'b', lw=2)\n",
    "#     plt.hist(sample, 30, normed=True, alpha=0.2)\n",
    "    seaborn.distplot(sample, kde=False, hist=True)\n",
    "    plt.annotate('3$\\sigma$', \n",
    "                     xy=(mu + 3*sigma, 0),  xycoords='data',\n",
    "                     xytext=(0, 100), textcoords='offset points',\n",
    "                     fontsize=15,\n",
    "                     arrowprops=dict(arrowstyle=\"->\",\n",
    "                                    connectionstyle=\"arc,angleA=180,armA=20,angleB=90,armB=15,rad=7\"))\n",
    "    plt.annotate('-3$\\sigma$', \n",
    "                     xy=(mu -3*sigma, 0), xycoords='data', \n",
    "                     xytext=(0, 100), textcoords='offset points',\n",
    "                     fontsize=15,\n",
    "                     arrowprops=dict(arrowstyle=\"->\",\n",
    "                                     connectionstyle=\"arc,angleA=180,armA=20,angleB=90,armB=15,rad=7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "\n",
    "plot_normal_sample(sample1, 0, 0.5)\n",
    "plt.title('Sample 1: $\\mu=0$, $\\sigma=0.5$')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_normal_sample(sample2, 1, 1)\n",
    "plt.title('Sample 2: $\\mu=1$, $\\sigma=1$')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print('Sample 1; estimated mean:', sample1.mean(), ' and std. dev.: ', sample1.std())\n",
    "print('Sample 2; estimated mean:', sample2.mean(), ' and std. dev.: ', sample2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Covariance](http://en.wikipedia.org/wiki/Covariance) is a measure of how much two random variables change together. \n",
    "$$\n",
    "\\operatorname{cov}(X,Y) = \\operatorname{E}{\\big[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])\\big]},\n",
    "$$\n",
    "$$\n",
    "\\operatorname{cov}(X,X) = s(X),\n",
    "$$\n",
    "\n",
    "* The sign of the covariance therefore shows the tendency in the linear relationship between the variables. \n",
    "* The magnitude of the covariance is not easy to interpret. \n",
    "* The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Understanding covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample_2d = np.array(list(zip(sample1, np.ones(len(sample1))))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(sample_2d[0,:], sample_2d[1,:], marker='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.cov(sample_2d) # computes covariance between the two components of the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "As the sample is only distributed along one axis, the covariance does not detects any relationship between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What happens when we rotate the sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def rotate_sample(sample, angle=-45):\n",
    "    'Rotates a sample by `angle` degrees.'\n",
    "    theta = (angle/180.) * np.pi\n",
    "    rot_matrix = np.array([[np.cos(theta), -np.sin(theta)], \n",
    "                           [np.sin(theta), np.cos(theta)]])\n",
    "    return sample.T.dot(rot_matrix).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rot_sample_2d = rotate_sample(sample_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(rot_sample_2d[0,:], rot_sample_2d[1,:], marker='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.cov(rot_sample_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A two-dimensional normally-distributed variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = [0,1]\n",
    "cov = [[1,0],[0,0.2]] # diagonal covariance, points lie on x or y-axis\n",
    "sample = np.random.multivariate_normal(mu,cov,1000).T\n",
    "plt.scatter(sample[0], sample[1], marker='x', alpha=0.29)\n",
    "\n",
    "estimated_mean = sample.mean(axis=1)\n",
    "estimated_cov = np.cov(sample)\n",
    "e_x,e_y = np.random.multivariate_normal(estimated_mean,estimated_cov,500).T\n",
    "\n",
    "plt.plot(e_x,e_y,'rx', alpha=0.47)\n",
    "x, y = np.mgrid[-4:4:.01, -1:3:.01]\n",
    "pos = np.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "rv = multivariate_normal(estimated_mean, estimated_cov)\n",
    "plt.contour(x, y, rv.pdf(pos), cmap=cm.viridis_r, lw=4)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This is better understood in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,5))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(x, y, rv.pdf(pos), cmap=cm.viridis_r, rstride=30, cstride=10, linewidth=1, alpha=0.47)\n",
    "ax.plot_wireframe(x, y, rv.pdf(pos), linewidth=0.47, alpha=0.47)\n",
    "ax.scatter(e_x, e_y, 0.4, marker='.', alpha=0.47)\n",
    "ax.axis('tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Again, what happens if we rotate the sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rot_sample = rotate_sample(sample)\n",
    "estimated_mean = rot_sample.mean(axis=1)\n",
    "estimated_cov = np.cov(rot_sample)\n",
    "e_x,e_y = np.random.multivariate_normal(estimated_mean,estimated_cov,500).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(rot_sample[0,:], rot_sample[1,:], marker='x', alpha=0.7)\n",
    "plt.title('\"Original\" data')\n",
    "plt.axis('equal')\n",
    "plt.subplot(122)\n",
    "plt.scatter(e_x, e_y, marker='o', color='g', alpha=0.7)\n",
    "plt.title('Sampled data')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Covariance captures the dependency and can model disposition of the \"original\" sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-4:4:.01, -3:3:.01]\n",
    "pos = np.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "rv = multivariate_normal(estimated_mean, estimated_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,5))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(x, y, rv.pdf(pos), cmap=cm.viridis_r, rstride=30, cstride=10, linewidth=1, alpha=0.47)\n",
    "ax.plot_wireframe(x, y, rv.pdf(pos), linewidth=0.47, alpha=0.47)\n",
    "ax.scatter(e_x, e_y, 0.4, marker='.', alpha=0.47)\n",
    "ax.axis('tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evolutionary Strategies\n",
    "\n",
    "We will be using DEAP again to present some of the ES main concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import array, random, time, copy\n",
    "\n",
    "from deap import base, creator, benchmarks, tools, algorithms\n",
    "\n",
    "random.seed(42) # Fixing a random seed: You should not do this in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we dive into the discussion lets code some support functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_problem_3d(problem, bounds, resolution=100., \n",
    "                    cmap=cm.viridis_r, rstride=10, cstride=10, \n",
    "                    linewidth=0.15, alpha=0.65, ax=None):\n",
    "    'Plots a given deap benchmark problem in 3D mesh.'\n",
    "    (minx,miny),(maxx,maxy) = bounds\n",
    "    x_range = np.arange(minx, maxx, (maxx-minx)/resolution)\n",
    "    y_range = np.arange(miny, maxy, (maxy-miny)/resolution)\n",
    "    \n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((len(x_range), len(y_range)))\n",
    "    \n",
    "    for i in range(len(x_range)):\n",
    "        for j in range(len(y_range)):\n",
    "            Z[i,j] = problem((x_range[i], y_range[j]))[0]\n",
    "    \n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(11,6))\n",
    "        ax = fig.gca(projection='3d')\n",
    "        \n",
    "    cset = ax.plot_surface(X, Y, Z, cmap=cmap, rstride=rstride, cstride=cstride, linewidth=linewidth, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_problem_controur(problem, bounds, optimum=None,\n",
    "                          resolution=100., cmap=cm.viridis_r, \n",
    "                          rstride=1, cstride=10, linewidth=0.15,\n",
    "                          alpha=0.65, ax=None):\n",
    "    'Plots a given deap benchmark problem as a countour plot'\n",
    "    (minx,miny),(maxx,maxy) = bounds\n",
    "    x_range = np.arange(minx, maxx, (maxx-minx)/resolution)\n",
    "    y_range = np.arange(miny, maxy, (maxy-miny)/resolution)\n",
    "    \n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((len(x_range), len(y_range)))\n",
    "    \n",
    "    for i in range(len(x_range)):\n",
    "        for j in range(len(y_range)):\n",
    "            Z[i,j] = problem((x_range[i], y_range[j]))[0]\n",
    "    \n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.gca()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.autoscale(tight=True)\n",
    "    \n",
    "    cset = ax.contourf(X, Y, Z, cmap=cmap, rstride=rstride, cstride=cstride, linewidth=linewidth, alpha=alpha)\n",
    "    \n",
    "    if optimum:\n",
    "        ax.plot(optimum[0], optimum[1], 'bx', linewidth=4, markersize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cov_ellipse(pos, cov, volume=.99, ax=None, fc='lightblue', ec='darkblue', alpha=1, lw=1):\n",
    "    ''' Plots an ellipse that corresponds to a bivariate normal distribution.\n",
    "    Adapted from http://www.nhsilbert.net/source/2014/06/bivariate-normal-ellipse-plotting-in-python/'''\n",
    "    from scipy.stats import chi2\n",
    "    from matplotlib.patches import Ellipse\n",
    "\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "\n",
    "    kwrg = {'facecolor':fc, 'edgecolor':ec, 'alpha':alpha, 'linewidth':lw}\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * np.sqrt(chi2.ppf(volume,2)) * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwrg)\n",
    "    ax.add_artist(ellip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why benchmarks (test) functions?\n",
    "\n",
    "In applied mathematics, [test functions](http://en.wikipedia.org/wiki/Test_functions_for_optimization), also known as artificial landscapes, are useful to evaluate characteristics of optimization algorithms, such as:\n",
    "\n",
    "* Velocity of convergence.\n",
    "* Precision.\n",
    "* Robustness.\n",
    "* General performance.\n",
    "\n",
    "DEAP has a number of test problems already implemented. See http://deap.readthedocs.org/en/latest/api/benchmarks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Bohachevsky benchmark problem](http://deap.readthedocs.org/en/latest/api/benchmarks.html#deap.benchmarks.bohachevsky)\n",
    "\n",
    "$$\\text{minimize } f(\\mathbf{x}) = \\sum_{i=1}^{N-1}(x_i^2 + 2x_{i+1}^2 - 0.3\\cos(3\\pi x_i) - 0.4\\cos(4\\pi x_{i+1}) + 0.7), \\mathbf{x}\\in \\left[-100,100\\right]^n,$$\n",
    "\n",
    "> Optimum in $\\mathbf{x}=\\mathbf{0}$, $f(\\mathbf{x})=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "current_problem = benchmarks.bohachevsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_problem_3d(current_problem, ((-10,-10), (10,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Bohachevsky problem has many local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_problem_3d(current_problem, ((-2.5,-2.5), (2.5,2.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "plot_problem_controur(current_problem, ((-2.5,-2.5), (2.5,2.5)), optimum=(0,0), ax=ax)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ($\\mu$,$\\lambda$) evolutionary strategy\n",
    "\n",
    "Some basic initialization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "search_space_dims = 2 # we want to plot the individuals so this must be 2\n",
    "\n",
    "MIN_VALUE, MAX_VALUE = -10., 10.\n",
    "MIN_STRAT, MAX_STRAT = 0.0000001, 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We are facing a minimization problem\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "\n",
    "# Evolutionary strategies need a location (mean)\n",
    "creator.create(\"Individual\", array.array, typecode='d', \n",
    "               fitness=creator.FitnessMin, strategy=None)\n",
    "# ...and a value of the strategy parameter.\n",
    "creator.create(\"Strategy\", array.array, typecode=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evolutionary strategy individuals are more complex than those we have seen so far.\n",
    "\n",
    "They need a custom creation/initialization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def init_univariate_es_ind(individual_class, strategy_class,\n",
    "                           size, min_value, max_value, \n",
    "                           min_strat, max_strat):\n",
    "    ind = individual_class(random.uniform(min_value, max_value) \n",
    "                           for _ in range(size))\n",
    "    # we modify the instance to include the strategy in run-time.\n",
    "    ind.strategy = strategy_class(random.uniform(min_strat, max_strat) for _ in range(size))\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox() \n",
    "toolbox.register(\"individual\", init_univariate_es_ind, \n",
    "                 creator.Individual, \n",
    "                 creator.Strategy,\n",
    "                 search_space_dims, \n",
    "                 MIN_VALUE, MAX_VALUE, \n",
    "                 MIN_STRAT, MAX_STRAT)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, \n",
    "                 toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How does an individual and a population looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ind = toolbox.individual()\n",
    "pop = toolbox.population(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_individual(individual, ax=None):\n",
    "    'Plots an ES indiviual as center and 3*sigma ellipsis.'\n",
    "    cov = np.eye(len(individual)) * individual.strategy\n",
    "    plot_cov_ellipse(individual, cov, volume=0.99, alpha=0.56, ax=ax)\n",
    "    if ax:\n",
    "        ax.scatter(individual[0], individual[1], \n",
    "                    marker='+', color='k', zorder=100)\n",
    "    else:\n",
    "        plt.scatter(individual[0], individual[1], \n",
    "                    marker='+', color='k', zorder=100)\n",
    "\n",
    "    \n",
    "def plot_population(pop, gen=None, max_gen=None, ax=None):\n",
    "    if gen:\n",
    "        plt.subplot(max_gen, 1, gen)\n",
    "        \n",
    "    for ind in pop:\n",
    "        plot_individual(ind, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_problem_controur(current_problem, ((-10,-10), (10,10)), optimum=(0,0))\n",
    "plot_individual(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_problem_controur(current_problem, ((-10,-10), (10,10)), optimum=(0,0))\n",
    "plot_population(pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mutation of an evolution strategy individual according to its strategy attribute. \n",
    "First the strategy is mutated according to an extended log normal rule, \n",
    "$$\n",
    "\\boldsymbol{\\sigma}_t = \\exp(\\tau_0 \\mathcal{N}_0(0, 1)) \\left[ \\sigma_{t-1, 1}\\exp(\\tau\n",
    "\\mathcal{N}_1(0, 1)), \\ldots, \\sigma_{t-1, n} \\exp(\\tau\n",
    "\\mathcal{N}_n(0, 1))\\right],\n",
    "$$\n",
    "with \n",
    "$$\\tau_0 =\n",
    "\\frac{c}{\\sqrt{2n}}\\text{ and }\\tau = \\frac{c}{\\sqrt{2\\sqrt{n}}},\n",
    "$$\n",
    "\n",
    "the individual is mutated by a normal distribution of mean 0 and standard deviation of $\\boldsymbol{\\sigma}_{t}$ (its current strategy). \n",
    "\n",
    "A recommended choice is $c=1$ when using a $(10,100)$ evolution strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "toolbox.register(\"mutate\", tools.mutESLogNormal, c=1, indpb=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Blend crossover on both, the individual and the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", tools.cxESBlend, alpha=0.1)\n",
    "toolbox.register(\"evaluate\", current_problem)\n",
    "toolbox.register(\"select\", tools.selBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mu_es, lambda_es = 3,21\n",
    "\n",
    "pop = toolbox.population(n=mu_es)\n",
    "hof = tools.HallOfFame(1)\n",
    "\n",
    "pop_stats = tools.Statistics(key=copy.deepcopy)\n",
    "pop_stats.register('pop', copy.deepcopy) # -- copies the populations themselves\n",
    "    \n",
    "pop, logbook = algorithms.eaMuCommaLambda(pop, toolbox, mu=mu_es, lambda_=lambda_es, \n",
    "        cxpb=0.6, mutpb=0.3, ngen=40, stats=pop_stats, halloffame=hof, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The final population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_problem_controur(current_problem, ((-10,-10), (10,10)), optimum=(0,0))\n",
    "plot_population(pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The plot (most probably) shows a \"dark blue\" ellipse as all individuals are overlapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how the evolutionary process took place in animated form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    'Updates all plots to match frame _i_ of the animation.'\n",
    "    ax.clear()\n",
    "    plot_problem_controur(current_problem, ((-10.1,-10.1), (10.1,10.1)), optimum=(0,0), ax=ax)\n",
    "    plot_population(logbook[i]['pop'], ax=ax)\n",
    "    ax.set_title('$t=$' +str(i))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.gca()\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(logbook), interval=300, blit=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How the population progressed as the evolution proceeded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=mu_es)\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "    \n",
    "pop, logbook = algorithms.eaMuCommaLambda(pop, toolbox, \n",
    "                                          mu=mu_es, lambda_=lambda_es, \n",
    "                                          cxpb=0.6, mutpb=0.3, \n",
    "                                          ngen=40, stats=stats, \n",
    "                                          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(7, 4))\n",
    "plt.plot(logbook.select('avg'), 'b-', label='Avg. fitness')\n",
    "plt.fill_between(range(len(logbook)), logbook.select('max'), logbook.select('min'), facecolor='blue', alpha=0.47)\n",
    "plt.plot(logbook.select('std'), 'm--', label='Std. deviation')\n",
    "plt.legend(frameon=True)\n",
    "plt.ylabel('Fitness'); plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What happens if we increase $\\mu$ and $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu_es, lambda_es = 10,100\n",
    "pop, logbook = algorithms.eaMuCommaLambda(toolbox.population(n=mu_es), toolbox, mu=mu_es, lambda_=lambda_es, \n",
    "        cxpb=0.6, mutpb=0.3, ngen=40, stats=stats, halloffame=hof, verbose=False)\n",
    "plt.figure(1, figsize=(7, 4))\n",
    "plt.plot(logbook.select('avg'), 'b-', label='Avg. fitness')\n",
    "plt.fill_between(range(len(logbook)), logbook.select('max'), logbook.select('min'), facecolor='blue', alpha=0.47)\n",
    "plt.plot(logbook.select('std'), 'm--', label='Std. deviation')\n",
    "plt.legend(frameon=True)\n",
    "plt.ylabel('Fitness'); plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Covariance Matrix Adaptation Evolutionary Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* In an evolution strategy, new candidate solutions are sampled according to a multivariate normal distribution in the $\\mathbb{R}^n$. \n",
    "* Recombination amounts to selecting a new mean value for the distribution. \n",
    "* Mutation amounts to adding a random vector, a perturbation with zero mean. \n",
    "* Pairwise dependencies between the variables in the distribution are represented by a covariance matrix. \n",
    "\n",
    "### The covariance matrix adaptation (CMA) is a method to update the covariance matrix of this distribution. \n",
    "\n",
    "> This is particularly useful, if the objective function $f()$ is ill-conditioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CMA-ES features\n",
    "\n",
    "* Adaptation of the covariance matrix amounts to learning a second order model of the underlying objective function.\n",
    "* This is similar to the approximation of the inverse Hessian matrix in the Quasi-Newton method in classical optimization. \n",
    "* In contrast to most classical methods, fewer assumptions on the nature of the underlying objective function are made. \n",
    "* *Only the ranking between candidate solutions is exploited* for learning the sample distribution and neither derivatives nor even the function values themselves are required by the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from deap import cma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A similar setup to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"evaluate\", current_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will place our start point by hand at $(5,5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cma_es = cma.Strategy(centroid=[5.0]*search_space_dims, sigma=5.0, lambda_=5*search_space_dims)\n",
    "toolbox.register(\"generate\", cma_es.generate, creator.Individual)\n",
    "toolbox.register(\"update\", cma_es.update)\n",
    "\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "# The CMA-ES algorithm converge with good probability with those settings\n",
    "pop, logbook = algorithms.eaGenerateUpdate(toolbox, ngen=60, stats=stats, \n",
    "                                           halloffame=hof, verbose=False)\n",
    "    \n",
    "print(\"Best individual is %s, fitness: %s\" % (hof[0], hof[0].fitness.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(7, 4))\n",
    "plt.plot(logbook.select('avg'), 'b-', label='Avg. fitness')\n",
    "plt.fill_between(range(len(logbook)), logbook.select('max'), logbook.select('min'), facecolor='blue', alpha=0.47)\n",
    "plt.plot(logbook.select('std'), 'm--', label='Std. deviation')\n",
    "plt.legend(frameon=True)\n",
    "plt.ylabel('Fitness'); plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OK, but wouldn't it be nice to have an animated plot of how CMA-ES progressed? \n",
    "\n",
    "* We need to do some coding to make this animation work.\n",
    "* We are going to create a class named `PlotableStrategy` that inherits from `deap.cma.Strategy`. This class logs the features we need to make the plots as evolution takes place. That is, for every iteration we store:\n",
    "    * Current centroid and covariance ellipsoid.\n",
    "    * Updated centroid and covariance.\n",
    "    * Sampled individuals.\n",
    "    * Evolution path.\n",
    "    \n",
    "_Note_: I think that DEAP's implementation of CMA-ES has the drawback of storing information that should be stored as part of \"individuals\". I leave this for an afternoon hack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt, log, exp\n",
    "class PlotableStrategy(cma.Strategy):\n",
    "    \"\"\"This is a modification of deap.cma.Strategy class.\n",
    "    We store the execution data in order to plot it.\n",
    "    **Note:** This class should not be used for other uses than\n",
    "    the one it is meant for.\"\"\"\n",
    "    \n",
    "    def __init__(self, centroid, sigma, **kargs):\n",
    "        \"\"\"Does the original initialization and then reserves \n",
    "        the space for the statistics.\"\"\"\n",
    "        super(PlotableStrategy, self).__init__(centroid, sigma, **kargs)\n",
    "        \n",
    "        self.stats_centroids = []\n",
    "        self.stats_new_centroids = []\n",
    "        self.stats_covs = []\n",
    "        self.stats_new_covs = []\n",
    "        self.stats_offspring = []\n",
    "        self.stats_offspring_weights = []\n",
    "        self.stats_ps = []\n",
    "    \n",
    "    def update(self, population):\n",
    "        \"\"\"Update the current covariance matrix strategy from the\n",
    "        *population*.\n",
    "        \n",
    "        :param population: A list of individuals from which to update the\n",
    "                           parameters.\n",
    "        \"\"\"\n",
    "        # -- store current state of the algorithm\n",
    "        self.stats_centroids.append(copy.deepcopy(self.centroid))\n",
    "        self.stats_covs.append(copy.deepcopy(self.C))\n",
    "        \n",
    "        \n",
    "        population.sort(key=lambda ind: ind.fitness, reverse=True)\n",
    "        \n",
    "        # -- store sorted offspring\n",
    "        self.stats_offspring.append(copy.deepcopy(population))\n",
    "        \n",
    "        old_centroid = self.centroid\n",
    "        self.centroid = np.dot(self.weights, population[0:self.mu])\n",
    "        \n",
    "        # -- store new centroid\n",
    "        self.stats_new_centroids.append(copy.deepcopy(self.centroid))\n",
    "        \n",
    "        c_diff = self.centroid - old_centroid\n",
    "        \n",
    "        \n",
    "        # Cumulation : update evolution path\n",
    "        self.ps = (1 - self.cs) * self.ps \\\n",
    "             + sqrt(self.cs * (2 - self.cs) * self.mueff) / self.sigma \\\n",
    "             * np.dot(self.B, (1. / self.diagD) \\\n",
    "                          * np.dot(self.B.T, c_diff))\n",
    "        \n",
    "        # -- store new evol path\n",
    "        self.stats_ps.append(copy.deepcopy(self.ps))\n",
    "        \n",
    "        hsig = float((np.linalg.norm(self.ps) / \n",
    "                sqrt(1. - (1. - self.cs)**(2. * (self.update_count + 1.))) / self.chiN\n",
    "                < (1.4 + 2. / (self.dim + 1.))))\n",
    "        \n",
    "        self.update_count += 1\n",
    "        \n",
    "        self.pc = (1 - self.cc) * self.pc + hsig \\\n",
    "                  * sqrt(self.cc * (2 - self.cc) * self.mueff) / self.sigma \\\n",
    "                  * c_diff\n",
    "        \n",
    "        # Update covariance matrix\n",
    "        artmp = population[0:self.mu] - old_centroid\n",
    "        self.C = (1 - self.ccov1 - self.ccovmu + (1 - hsig) \\\n",
    "                   * self.ccov1 * self.cc * (2 - self.cc)) * self.C \\\n",
    "                + self.ccov1 * np.outer(self.pc, self.pc) \\\n",
    "                + self.ccovmu * np.dot((self.weights * artmp.T), artmp) \\\n",
    "                / self.sigma**2\n",
    "        \n",
    "        # -- store new covs\n",
    "        self.stats_new_covs.append(copy.deepcopy(self.C))\n",
    "        \n",
    "        self.sigma *= np.exp((np.linalg.norm(self.ps) / self.chiN - 1.) \\\n",
    "                                * self.cs / self.damps)\n",
    "        \n",
    "        self.diagD, self.B = np.linalg.eigh(self.C)\n",
    "        indx = np.argsort(self.diagD)\n",
    "        \n",
    "        self.cond = self.diagD[indx[-1]]/self.diagD[indx[0]]\n",
    "        \n",
    "        self.diagD = self.diagD[indx]**0.5\n",
    "        self.B = self.B[:, indx]\n",
    "        self.BD = self.B * self.diagD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is now possible to use/test our new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"evaluate\", current_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "max_gens = 40\n",
    "cma_es = PlotableStrategy(centroid=[5.0]*search_space_dims, sigma=1.0, lambda_=5*search_space_dims)\n",
    "toolbox.register(\"generate\", cma_es.generate, creator.Individual)\n",
    "toolbox.register(\"update\", cma_es.update)\n",
    "\n",
    "# The CMA-ES algorithm converge with good probability with those settings\n",
    "a = algorithms.eaGenerateUpdate(toolbox, ngen=max_gens, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Me can now code the `animate_cma_es()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm=colors.Normalize(vmin=np.min(cma_es.weights), vmax=np.max(cma_es.weights))\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def animate_cma_es(gen):\n",
    "    ax.cla()\n",
    "    plot_problem_controur(current_problem, ((-11,-11), (11,11)), optimum=(0,0), ax=ax)\n",
    "    \n",
    "    plot_cov_ellipse(cma_es.stats_centroids[gen], cma_es.stats_covs[gen], volume=0.99, alpha=0.29, ax=ax)\n",
    "    ax.plot(cma_es.stats_centroids[gen][0], cma_es.stats_centroids[gen][1], 'ro', markeredgecolor = 'none', ms=10)\n",
    "    \n",
    "    plot_cov_ellipse(cma_es.stats_new_centroids[gen], cma_es.stats_new_covs[gen], volume=0.99, \n",
    "                     alpha=0.29, fc='green', ec='darkgreen', ax=ax)\n",
    "    ax.plot(cma_es.stats_new_centroids[gen][0], cma_es.stats_new_centroids[gen][1], 'go', markeredgecolor = 'none', ms=10)\n",
    "    \n",
    "    for i in range(gen+1):\n",
    "        if i == 0:\n",
    "            ax.plot((0,cma_es.stats_ps[i][0]),\n",
    "                     (0,cma_es.stats_ps[i][1]), 'b--')\n",
    "        else:\n",
    "            ax.plot((cma_es.stats_ps[i-1][0],cma_es.stats_ps[i][0]),\n",
    "                     (cma_es.stats_ps[i-1][1],cma_es.stats_ps[i][1]),'b--')\n",
    "            \n",
    "    for i,ind in enumerate(cma_es.stats_offspring[gen]):\n",
    "        if i < len(cma_es.weights):\n",
    "            color = sm.to_rgba(cma_es.weights[i])\n",
    "        else:\n",
    "            color= sm.to_rgba(norm.vmin)\n",
    "        ax.plot(ind[0], ind[1], 'o', color = color, ms=5, markeredgecolor = 'none')\n",
    "    \n",
    "    ax.set_ylim((-10,10))\n",
    "    ax.set_xlim((-10,10))\n",
    "    ax.set_title('$t=$' +str(gen))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CMA-ES progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.gca()\n",
    "anim = animation.FuncAnimation(fig, animate_cma_es, frames=max_gens, interval=300, blit=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Current centroid and covariance: **red**.\n",
    "* Updated centroid and covariance: **green**. \n",
    "* Sampled individuals: **shades of gray representing their corresponding weight**.\n",
    "* Evolution path: **blue line starting in (0,0)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework\n",
    "\n",
    "1. Make an animated plot with the covariance update process. You can rely on the notebook of the previous demonstration class.\n",
    "2. Compare ES, CMA-ES and a genetic algortihm.\n",
    "2. How do you think that evolutionary strategies and CMA-ES should be modified in order to cope with combinatorial problems?\n",
    "3. How can evolution strategies be improved?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<hr/>\n",
    "<div class=\"container-fluid\">\n",
    "  <div class='well'>\n",
    "      <div class=\"row\">\n",
    "          <div class=\"col-md-3\" align='center'>\n",
    "              <img align='center'alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\"/>\n",
    "          </div>\n",
    "          <div class=\"col-md-9\">\n",
    "              This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).\n",
    "          </div>\n",
    "      </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# To install run: pip install version_information\n",
    "%load_ext version_information\n",
    "%version_information scipy, numpy, matplotlib, seaborn, deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# this code is here for cosmetic reasons\n",
    "from IPython.core.display import HTML\n",
    "from urllib.request import urlopen\n",
    "HTML(urlopen('https://raw.githubusercontent.com/lmarti/jupyter_custom/master/custom.include').read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
